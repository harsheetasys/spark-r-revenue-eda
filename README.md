# ğŸš€ Big Data Revenue Analysis with Spark + R

This project performs scalable exploratory data analysis (EDA) on historical retail transactions using **Apache Spark**, then generates clean, business-ready revenue trend visualizations using **R (ggplot2)**.

---

## ğŸ“‚ Dataset

- **Source**: Sample retail order dataset (classicmodels-style)
- **Rows**: ~3,000+
- **Columns**:
  - `ORDERDATE`: Date of transaction (MM/DD/YYYY HH:MM)
  - `SALES`: Revenue amount
  - Other fields: `PRODUCTLINE`, `CUSTOMERNAME`, `COUNTRY`, etc.

---

## ğŸ§  Objective

> Can we uncover monthly sales trends and seasonal patterns from raw transactional data?

---

## ğŸ›  Tools Used

| Layer         | Stack                                  |
|---------------|----------------------------------------|
| ğŸš€ Big Data    | Apache Spark (PySpark on Colab)        |
| ğŸ“Š Visualization | R, ggplot2                           |
| ğŸ§¹ Wrangling   | Spark SQL, `withColumn`, `groupBy`     |
| ğŸ” Export      | `coalesce(1).write.csv()` from Spark   |

---

## ğŸ›  Processing Steps

1. **Loaded large CSV** using PySpark with schema inference
2. **Parsed date field** with `to_timestamp()`, extracted `month` and `year`
3. **Grouped revenue** by `(year, month)` using `groupBy().agg()`
4. **Exported** clean results to CSV for external R analysis
5. **Visualized trends** in `ggplot2` using a time series line chart

---

## ğŸ“Š Results & Business Insight

| Insight Type         | Example Finding |
|----------------------|-----------------|
| âœ… Seasonality        | Revenue spikes during Q4 (holiday period) |
| ğŸ“‰ Dips               | February often lowest-performing month |
| ğŸ“ˆ Use Case           | Highlights inventory & staffing seasonality |

---

## ğŸ“ˆ Final Output

- PySpark: Monthly revenue grouped into a DataFrame
- R: Line chart of monthly revenue over time

